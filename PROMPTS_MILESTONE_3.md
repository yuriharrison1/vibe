# Prompts Milestone 3 - Execu√ß√£o e Tracking de Testes

Execute estes prompts na ordem. Cada prompt √© autocontido.

---

## PROMPT 0: Atualizar documenta√ß√£o Milestone 2

```
Atualize a documenta√ß√£o para refletir a conclus√£o do Milestone 2.

1. Atualize CHANGELOG.md:
   - Adicionar se√ß√£o [0.3.0] - Milestone 2
   - Listar features implementadas:
     - Gera√ß√£o autom√°tica de testes (`src/test_generator.py`)
     - Integra√ß√£o autom√°tica em `objective new`
     - Comando `vibe objective generate-tests <id>`
     - Valida√ß√£o de integridade em `project check`
     - Rollback se falha na gera√ß√£o
   - Listar testes criados:
     - `tests/test_test_generator.py`
     - Testes de integra√ß√£o CLI atualizados

2. Verifique pyproject.toml:
   - Confirmar vers√£o 0.3.0

3. Verifique src/__init__.py:
   - Confirmar __version__ = "0.3.0"

Crit√©rio de aceita√ß√£o:
- CHANGELOG completo e atualizado
- Vers√£o 0.3.0 consistente em todos os arquivos
- Documenta√ß√£o reflete estado atual do projeto
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
vibe --version  # deve mostrar 0.3.0
cat CHANGELOG.md | head -50
```

---

## PROMPT 1/7: Estender schema SQLite para tracking de testes

```
Leia scope.md se√ß√£o "9. Persist√™ncia" e archeture.md.

Atualize src/database.py para adicionar tracking de testes:

1. Nova tabela test_runs:
   - id TEXT PRIMARY KEY (UUID)
   - objective_id TEXT NOT NULL (FK para objectives.id)
   - test_file TEXT NOT NULL (caminho relativo do arquivo de teste)
   - test_name TEXT NOT NULL (nome da fun√ß√£o de teste)
   - status TEXT NOT NULL (PASSED, FAILED, SKIPPED, ERROR)
   - error_message TEXT (mensagem de erro se falhou)
   - duration REAL (dura√ß√£o em segundos)
   - run_at TEXT NOT NULL (timestamp ISO)
   - FOREIGN KEY (objective_id) REFERENCES objectives(id)

2. Nova tabela test_summary:
   - id TEXT PRIMARY KEY (UUID)
   - objective_id TEXT NOT NULL (FK)
   - total_tests INTEGER NOT NULL
   - passed INTEGER NOT NULL
   - failed INTEGER NOT NULL
   - skipped INTEGER NOT NULL
   - error INTEGER NOT NULL
   - last_run TEXT NOT NULL (timestamp ISO)
   - FOREIGN KEY (objective_id) REFERENCES objectives(id)

3. Adicionar m√©todos √† classe Database:
   - save_test_run(test_run: TestRun) -> bool
   - get_test_runs(objective_id: str) -> List[TestRun]
   - get_latest_test_run(objective_id: str) -> Optional[TestRun]
   - save_test_summary(summary: TestSummary) -> bool
   - get_test_summary(objective_id: str) -> Optional[TestSummary]
   - update_test_summary(objective_id: str, summary: TestSummary) -> bool

4. Migra√ß√£o autom√°tica:
   - Detectar tabelas inexistentes
   - Criar novas tabelas se necess√°rio
   - Preservar dados existentes

Crit√©rio de aceita√ß√£o:
- Schema estendido com novas tabelas
- M√©todos CRUD funcionais
- Migra√ß√£o autom√°tica sem perda de dados
- Foreign keys funcionando corretamente
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
python -c "
from src.database import Database
from pathlib import Path
db = Database(Path('test_migration.db'))
print('‚úì Schema migrado com sucesso')
"
rm -f test_migration.db
```

---

## PROMPT 2/7: Criar modelos para test runs e summary

```
Atualize src/models.py para adicionar modelos de tracking.

1. Classe TestStatus (Enum):
   - PASSED
   - FAILED
   - SKIPPED
   - ERROR

2. Classe TestRun (dataclass):
   - id: str (UUID)
   - objective_id: str
   - test_file: str (Path relativo)
   - test_name: str
   - status: TestStatus
   - error_message: Optional[str]
   - duration: float (segundos)
   - run_at: datetime

3. Classe TestSummary (dataclass):
   - id: str (UUID)
   - objective_id: str
   - total_tests: int
   - passed: int
   - failed: int
   - skipped: int
   - error: int
   - last_run: datetime

4. Adicionar m√©todos:
   - to_dict() para ambas as classes
   - from_dict() para ambas as classes
   - M√©todo TestSummary.is_passing() -> bool (True se todos passaram)
   - M√©todo TestSummary.success_rate() -> float (% de testes passando)

Crit√©rio de aceita√ß√£o:
- Modelos tipados com mypy
- Serializa√ß√£o/deserializa√ß√£o funcional
- M√©todos auxiliares implementados
- Valida√ß√£o de campos obrigat√≥rios
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
python -c "
from src.models import TestRun, TestSummary, TestStatus
from datetime import datetime
run = TestRun(
    id='test-id',
    objective_id='obj-id',
    test_file='test.py',
    test_name='test_foo',
    status=TestStatus.PASSED,
    error_message=None,
    duration=0.5,
    run_at=datetime.now()
)
print('‚úì Models criados:', run.test_name)
"
```

---

## PROMPT 3/7: Criar executor de testes (test runner)

```
Crie src/test_runner.py para executar testes e coletar resultados.

Implemente:

1. Classe TestRunner:
   - __init__(db: Database)
   - Configura√ß√£o do pytest programaticamente

2. M√©todo run_objective_tests(objective_id: str) -> TestSummary:
   - Localizar diret√≥rio de testes: tests/objectives/{objective_id}/
   - Validar que diret√≥rio existe
   - Executar pytest programaticamente usando pytest.main() ou subprocess
   - Capturar resultados de cada teste
   - Parsear output do pytest (usar --json-report se dispon√≠vel, ou --verbose)
   - Criar TestRun para cada teste executado
   - Salvar TestRuns no banco
   - Calcular TestSummary
   - Salvar TestSummary no banco
   - Retornar TestSummary

3. M√©todo run_all_tests() -> Dict[str, TestSummary]:
   - Buscar todos os objetivos no banco
   - Para cada objetivo, executar run_objective_tests()
   - Retornar dict {objective_id: TestSummary}

4. Tratamento de erros:
   - Objetivo sem diret√≥rio de testes
   - Testes com erro de sintaxe
   - Testes que n√£o executam
   - Timeout de execu√ß√£o

5. Output formatado:
   - Exibir progresso durante execu√ß√£o
   - Mostrar cada teste executado
   - Resumo final com estat√≠sticas

Crit√©rio de aceita√ß√£o:
- Execu√ß√£o program√°tica de pytest funcional
- Resultados capturados corretamente
- Persist√™ncia autom√°tica de resultados
- Tratamento robusto de erros
- Output claro e informativo
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
python -c "
from src.test_runner import TestRunner
from src.database import Database
from pathlib import Path
db = Database(Path('state/vibe.db'))
runner = TestRunner(db)
print('‚úì TestRunner criado')
"
```

---

## PROMPT 4/7: Implementar comando 'vibe test run'

```
Crie grupo de comandos 'test' em src/cli.py.

Implemente:

@cli.group()
def test():
    """Gerencia execu√ß√£o de testes."""
    pass

@test.command(name="run")
@click.argument("objective_id", required=False)
@click.option("--all", is_flag=True, help="Executar testes de todos os objetivos")
@click.option("--verbose", "-v", is_flag=True, help="Mostrar output detalhado")
def test_run(objective_id: Optional[str], all: bool, verbose: bool) -> None:
    """Executa testes de um objetivo espec√≠fico ou todos."""

    1. Valida√ß√µes:
       - Se n√£o passar --all nem objective_id: erro com mensagem
       - Se passar ambos: erro com mensagem
       - Se objetivo n√£o existir: erro
       - Se objetivo n√£o tiver testes: aviso

    2. Execu√ß√£o:
       - Criar TestRunner
       - Se objective_id: executar run_objective_tests()
       - Se --all: executar run_all_tests()
       - Exibir progresso em tempo real

    3. Output:
       - Modo normal: resumo compacto
         ```
         üß™ Executando testes para objetivo: {nome}

         ‚úÖ test_foo.py::test_basic ... PASSED (0.5s)
         ‚ùå test_bar.py::test_edge ... FAILED (0.2s)

         üìä Resultado:
            Total: 2
            ‚úÖ Passou: 1
            ‚ùå Falhou: 1
            Taxa de sucesso: 50%
         ```

       - Modo verbose: mostrar detalhes de erros
         ```
         ‚ùå test_bar.py::test_edge
            AssertionError: expected True, got False
            > assert result == expected
         ```

    4. Exit code:
       - 0 se todos passaram
       - 1 se algum falhou
       - 2 se erro de execu√ß√£o

Crit√©rio de aceita√ß√£o:
- Comando funcional com valida√ß√µes
- Output claro e formatado
- Modo verbose detalhado
- Exit code correto
- Integra√ß√£o com TestRunner
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
vibe test --help
# Criar objetivo com testes primeiro
vibe objective new
# Copiar ID e executar
vibe test run <ID>
vibe test run --all
```

---

## PROMPT 5/7: Implementar comando 'vibe objective status'

```
Adicione comando status ao grupo objective em src/cli.py.

Implemente:

@objective.command(name="status")
@click.argument("objective_id", required=False)
@click.option("--all", is_flag=True, help="Status de todos os objetivos")
@click.option("--verbose", "-v", is_flag=True, help="Mostrar detalhes dos testes")
def objective_status(objective_id: Optional[str], all: bool, verbose: bool) -> None:
    """Exibe status de testes de um ou todos os objetivos."""

    1. Se objective_id fornecido:
       - Buscar objetivo no banco
       - Buscar √∫ltimo TestSummary
       - Exibir status do objetivo:
         ```
         üìã Objetivo: {nome}
         ID: {id}
         Status: {status}
         Tipo(s): {tipos}

         üß™ Testes:
            √öltima execu√ß√£o: {timestamp}
            Total: {total}
            ‚úÖ Passou: {passed}
            ‚ùå Falhou: {failed}
            ‚è≠Ô∏è  Pulado: {skipped}
            ‚ö†Ô∏è  Erro: {error}
            Taxa de sucesso: {rate}%

         Estado: {"‚úÖ APROVADO" se todos passaram else "‚ùå FALHOU"}
         ```

    2. Se --all:
       - Listar todos os objetivos
       - Para cada um, mostrar resumo compacto:
         ```
         abc123de | Criar CLI | ‚úÖ 5/5 (100%) | √öltima execu√ß√£o: 2h atr√°s
         def456gh | Validador | ‚ùå 3/5 (60%)  | √öltima execu√ß√£o: 1h atr√°s
         ```

    3. Se --verbose:
       - Mostrar lista de testes individuais
       - Incluir nomes dos arquivos de teste
       - Mostrar dura√ß√£o de cada teste

    4. Casos especiais:
       - Objetivo sem testes ainda executados: "‚è∏Ô∏è  Testes n√£o executados"
       - Objetivo sem diret√≥rio de testes: "‚ö†Ô∏è  Testes n√£o gerados"

Crit√©rio de aceita√ß√£o:
- Status preciso refletindo realidade
- Formata√ß√£o clara e informativa
- Modo all com vis√£o geral
- Modo verbose com detalhes
- Timestamp humanizado (ex: "2h atr√°s")
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
vibe objective status <ID>
vibe objective status --all
vibe objective status <ID> --verbose
```

---

## PROMPT 6/7: Implementar health check no 'vibe project check'

```
Atualize src/validator.py para incluir valida√ß√£o de testes.

Adicione ao StructureValidator:

1. M√©todo check_test_health() -> List[str]:
   - Para cada objetivo no banco:
     - Verificar se tem testes gerados
     - Verificar se testes foram executados
     - Verificar se testes est√£o passando
   - Retornar lista de problemas encontrados:
     - "Objetivo {id} n√£o tem testes gerados"
     - "Objetivo {id} nunca teve testes executados"
     - "Objetivo {id} tem testes falhando ({failed}/{total})"
     - "Objetivo {id} marcado como CONCLUIDO mas testes falhando"

2. Atualizar m√©todo validate() em src/cli.py:
   - Adicionar se√ß√£o "üß™ Valida√ß√£o de Testes"
   - Chamar check_test_health()
   - Exibir problemas encontrados
   - Falhar se:
     - Objetivo marcado como CONCLUIDO com testes falhando
     - Objetivo ATIVO sem testes executados h√° mais de 24h

3. Adicionar warnings (n√£o bloqueia):
   - Testes nunca executados
   - Taxa de sucesso < 100%

4. Output esperado:
   ```
   üß™ Valida√ß√£o de Testes

   ‚úÖ Objetivo abc123: 5/5 testes passando
   ‚ö†Ô∏è  Objetivo def456: 3/5 testes passando (60%)
   ‚ùå Objetivo ghi789: Marcado como CONCLUIDO mas 2 testes falhando

   Resultado: ‚ùå FALHOU
   Problemas encontrados: 1
   Avisos: 1
   ```

Crit√©rio de aceita√ß√£o:
- Valida√ß√£o de sa√∫de dos testes implementada
- Bloqueio de objetivos conclu√≠dos com testes falhando
- Warnings informativos
- Integra√ß√£o com vibe project check
- Mensagens claras
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
vibe project check
# Deve validar testes al√©m da estrutura
```

---

## PROMPT 7/7: Criar testes e atualizar documenta√ß√£o

```
Finalize o Milestone 3 com testes e documenta√ß√£o.

1. Crie tests/test_test_runner.py:
   - test_run_objective_tests(): criar objetivo, gerar testes, executar
   - test_run_all_tests(): m√∫ltiplos objetivos
   - test_test_results_persisted(): verificar persist√™ncia no banco
   - test_summary_calculation(): validar c√°lculos de summary
   - test_error_handling(): testar casos de erro
   - Usar tmp_path e mock do pytest

2. Atualize tests/test_cli.py:
   - test_test_run_command(): testar comando test run
   - test_test_run_all(): testar --all flag
   - test_objective_status(): testar comando status
   - test_objective_status_all(): testar status --all
   - test_health_check_integration(): validar integra√ß√£o com project check

3. Atualize tests/test_database.py:
   - test_test_runs_crud(): testar m√©todos de TestRun
   - test_test_summary_crud(): testar m√©todos de TestSummary
   - test_foreign_key_constraint(): validar constraints

4. Atualize CHANGELOG.md:
   - Adicionar se√ß√£o [0.4.0] - Milestone 3
   - Listar features:
     - Execu√ß√£o de testes via CLI (`vibe test run`)
     - Tracking de resultados no SQLite
     - Comando `vibe objective status`
     - Health check integrado em `vibe project check`
     - TestRunner com execu√ß√£o program√°tica
   - Listar arquivos criados:
     - src/test_runner.py
     - Novos modelos: TestRun, TestSummary, TestStatus
     - Novas tabelas: test_runs, test_summary
     - tests/test_test_runner.py

5. Atualize pyproject.toml:
   - Vers√£o: 0.4.0

6. Atualize src/__init__.py:
   - __version__ = "0.4.0"

7. Atualize README.md:
   - Status: Milestone 3 ‚úÖ conclu√≠do
   - Badge: ![Milestone 3](https://img.shields.io/badge/milestone-3%20complete-green)
   - Adicionar exemplos:
     ```bash
     # Executar testes de um objetivo
     vibe test run <ID>

     # Executar todos os testes
     vibe test run --all

     # Ver status dos testes
     vibe objective status <ID>
     vibe objective status --all

     # Health check do projeto
     vibe project check
     ```

Crit√©rio de aceita√ß√£o:
- Todos os testes passam
- Cobertura > 80% nos novos arquivos
- CHANGELOG atualizado
- Vers√£o 0.4.0
- README reflete Milestone 3
- Documenta√ß√£o clara e completa
```

**Teste ap√≥s executar:**
```bash
source .venv/bin/activate
pytest -v
pytest --cov=src --cov-report=html
vibe --version  # deve mostrar 0.4.0
git diff README.md CHANGELOG.md
```

---

## Checklist Milestone 3

Ap√≥s todos os prompts:

- [ ] Schema SQLite estendido (test_runs, test_summary)
- [ ] Modelos TestRun e TestSummary criados
- [ ] TestRunner implementado
- [ ] Comando `vibe test run` funcional
- [ ] Comando `vibe objective status` funcional
- [ ] Health check integrado em `project check`
- [ ] Testes do test_runner passando
- [ ] Testes de CLI atualizados
- [ ] Testes de database atualizados
- [ ] Documenta√ß√£o atualizada
- [ ] Vers√£o 0.4.0

**Crit√©rios de aceite do Milestone 3:**
‚úÖ Status reflete realidade
‚úÖ Falha bloqueia progresso
‚úÖ Estado persistente correto

---

## Comandos √∫teis

```bash
# Ativar ambiente
source .venv/bin/activate

# Criar objetivo e gerar testes
vibe objective new

# Executar testes de um objetivo
vibe test run <ID>

# Executar todos os testes
vibe test run --all --verbose

# Ver status
vibe objective status <ID>
vibe objective status --all

# Health check completo
vibe project check

# Rodar suite completa de testes
pytest -v --cov=src --cov-report=html

# Verificar cobertura do test_runner
pytest --cov=src.test_runner --cov-report=term-missing

# Limpar database de teste
rm -f state/vibe.db
rm -rf tests/objectives/*
```

---

## Notas importantes

1. **Estado √© verdade:** O banco SQLite sempre reflete o estado real dos testes. Nada √© assumido.

2. **Execu√ß√£o obrigat√≥ria:** Antes de marcar objetivo como CONCLUIDO, testes devem ser executados e passar.

3. **Bloqueio autom√°tico:** `project check` falha se objetivo conclu√≠do tem testes falhando.

4. **Rastreabilidade completa:** Cada execu√ß√£o de teste √© registrada com timestamp, dura√ß√£o e resultado.

5. **Health check cont√≠nuo:** Valida√ß√£o de sa√∫de dos testes √© parte integral do `project check`.

6. **Exit codes corretos:** Comandos retornam c√≥digos apropriados para integra√ß√£o com CI/CD.

7. **Output informativo:** Sempre mostrar progresso, estat√≠sticas e estado atual de forma clara.

---

## Depend√™ncias adicionais

Caso precise instalar plugin do pytest para JSON report:

```bash
pip install pytest-json-report
```

Ou use parsing do output verbose do pytest diretamente (prefer√≠vel para manter depend√™ncias m√≠nimas).

---

## Integra√ß√£o futura (Milestone 4+)

Este milestone prepara o terreno para:
- Bloqueio autom√°tico de avan√ßo se testes falharem
- Integra√ß√£o com pre-commit hooks
- Valida√ß√£o antes de permitir IA modificar c√≥digo
- Dashboards de qualidade
- Hist√≥rico de execu√ß√µes para detec√ß√£o de regress√£o
